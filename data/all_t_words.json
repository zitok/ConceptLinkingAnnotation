[{"name": "Reinforcement Learning", "time": 1, "sents": ["DeepLearning4J/RL4J examples of Reinforcement Learning are available here:"]}, {"name": "Neural Networks", "time": 6, "sents": ["Neural Networks work by processing and updating MultiDimensional arrays of numeric values.", "Simple, straightforward, and focussed on image recognition, a task that Neural Networks do well.", "For more details on the thresholding approach, see  Strom, 2015 - Scalable Distributed DNN Training using Commodity GPU Cloud Computing  and  Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks .", "Neural Networks for NLP?", "Neural Networks, in particular, have a wide variety of hyperparameters.", "This is more likely an issue with deeper Neural Networks."]}, {"name": "Stanford University", "time": 1, "sents": ["TinyImageNet is the default course challenge for CS321n at Stanford University."]}, {"name": "False Alarm Rate", "time": 1, "sents": ["False Alarm Rate (FAR) reflects rate of misclassified to classified records  http://ro.ecu.edu.au/cgi/viewcontent.cgi?article=1058&context=isw  Note: value returned will differ depending on number of classes and settings."]}, {"name": "Macro-average AUC", "time": 1, "sents": ["Macro-average AUC for all outcomes"]}, {"name": "OS X", "time": 5, "sents": ["You can install OpenBLAS on OS X with Home Science:", "Make sure to read this if you are on OS X (ensure gcc 5.x is setup and you aren't using clang): https://github.com/deeplearning4j/deeplearning4j/issues/2668", "Note that Deeplearning4j is designed to work on most platforms (Windows, OS X, and Linux) and is also includes multiple \"flavors\" depending on the computing architecture you choose to utilize.", "This script will work on both Linux and OS X platforms.", "Installing ATLAS on OS X is a somewhat complicated and lengthy process."]}, {"name": "Home Science", "time": 1, "sents": ["You can install OpenBLAS on OS X with Home Science:"]}, {"name": "Deeplearning4j Model Zoo", "time": 1, "sents": ["Link:  Deeplearning4j Model Zoo"]}, {"name": "Google News Corpus", "time": 1, "sents": ["The  Google News Corpus model  we use to test the accuracy of our trained nets is hosted on S3."]}, {"name": "Skip Connections", "time": 1, "sents": ["with Skip Connections"]}, {"name": "Get DL4J SameDiffLayer", "time": 1, "sents": ["Get DL4J SameDiffLayer."]}, {"name": "Eclipse Deeplearning4j", "time": 8, "sents": ["Eclipse Deeplearning4j supports certain autoencoder layers such as variational autoencoders.", "The iterators included in Eclipse Deeplearning4j help with either user-provided data, or automatic loading of common benchmarking datasets such as MNIST and IRIS.", "The Eclipse Deeplearning4j libraries come with a lot of functionality, and we've put together this cheat sheet to help users assemble neural networks and use tensors faster.", "All layers available in Eclipse Deeplearning4j can be used either in a   or  .", "In Eclipse Deeplearning4j a vertex is a type of layer that acts as a node in a  .", "Before contributing, make sure you know the structure of all of the Eclipse Deeplearning4j libraries.", "Listeners allow users to \"hook\" into certain events in Eclipse Deeplearning4j.", "The   class is the simplest network configuration API available in Eclipse Deeplearning4j."]}, {"name": "Labeled Faces", "time": 1, "sents": ["LFW iterator - Labeled Faces from the Wild dataset  See  http://vis-www.cs.umass.edu/lfw/  13233 images total, with 5749 classes."]}, {"name": "AsyncTask Results", "time": 1, "sents": ["Once completed, we passed the output INDArray as the AsyncTask  Results  to onPostExecute() where the the UI was updated to demonstrate the classification results."]}, {"name": "Use LossFunctions.LossFunction.values", "time": 1, "sents": ["Use LossFunctions.LossFunction.values().foreach { println } to see what loss functions are available."]}, {"name": "DataSet RDD", "time": 2, "sents": ["Fit the DataSet RDD", "Fit the DataSet RDD."]}, {"name": "Java APIs", "time": 1, "sents": ["If you want to use the Scala-style method of programming, you can switch back and forth between the Scala and Java APIs for the Spark RDD."]}, {"name": "Spark RDD", "time": 5, "sents": ["If you want to use the Scala-style method of programming, you can switch back and forth between the Scala and Java APIs for the Spark RDD.", "Assuming you have already loaded your data into a Spark RDD, pass the   and   to the class.", "It builds a Spark RDD from the relatively small dataset and runs an analysis against it.", "Once we're certain that the schema and transformations are what we want, we can read the CSV into a  Spark RDD  and execute our transformation with DataVec.", "This example loads data into a Spark RDD."]}, {"name": "Apache Spark", "time": 11, "sents": ["In order to get OpenBLAS to work with Apache Spark, you will also need to do the following:", "Deeplearning4j supports neural network training on a cluster of CPU or GPU machines using Apache Spark.", "One of the way that Apache Spark improves performance is by allowing users to cache data in memory.", "Apache Spark is distributed with versions that support both Scala 2.10 and Scala 2.11.", "This section will cover the technical details of Deeplearning4j's Apache Spark gradient sharing training implementation.", "If you have loaded your data into Apache Spark, DataVec has a special   class which can generate histograms, collect statistics, and return information about the quality of the data.", "Hadoop  was originally developed for storing and processing large amounts of data; however, with times comes innovation and  Apache Spark  was eventually developed for faster large-scale data processing, touting up to a 100x improvement over Hadoop.", "DeepLearning4j supports distributed training in the Apache Spark environment and  Aeron  for high performance inter-node communication outside of Spark.", "This is essentially a Spark limitation: DL4J could (in principle) implement functionality to recover from a failed master and continue training, but Apache Spark does not support fault tolerance for the master node.", "Once you've created your   using your  , and you've either loaded your dataset into a Apache Spark   or have a   that load your dataset, you can execute a transform.", "If you're using Apache Spark, functions will iterate over the dataset and load it into a Spark   and convert the raw data format into a  ."]}, {"name": "Calculate ROC AUC", "time": 1, "sents": ["Calculate ROC AUC (area under ROC curve) or AUCPR (area under precision recall curve) for a MultiLayerNetwork or ComputationGraph"]}, {"name": "Troubleshooting Guides", "time": 1, "sents": ["Problems and Troubleshooting Guides"]}, {"name": "Spark Submit", "time": 1, "sents": ["The user can submit a uber jar to Spark Submit for execution with the right options."]}, {"name": "Instructor Tom Hanlon", "time": 1, "sents": ["Instructor Tom Hanlon provides an overview of a simple classifier over Iris data built in Keras with a Theano backend, and exported and loaded into Deeplearning4j:"]}, {"name": "UDP Unicast", "time": 1, "sents": ["Since message retransmission in UDP Unicast transport is handled by the Master node (which typically has low utilization) and since message passing is asynchronous, we simply require that update communication time is less than network iteration time for performance - which is usually the case."]}, {"name": "JVM GC", "time": 3, "sents": ["With workspaces enabled, all memory used during training will be reusable and tracked without the JVM GC interference.", "Subsequently, it detaches the resulting   from the workspaces, thus providing you with independent   which will be handled by the JVM GC.", "training or evaluation/inference loops - if you do not, the NDArrays and their off-heap (and GPU) resources are reclaimed using the JVM GC, which might introduce severe latency and possible out of memory situations."]}, {"name": "Simple RNN", "time": 1, "sents": ["Simple RNN - aka \"vanilla\" RNN is the simplest type of recurrent neural network layer."]}, {"name": "Recurrent Neural Networks", "time": 5, "sents": ["The examples folder for Recurrent Neural Networks has the following:", "For larger or more complex neural networks like Convolutional or Recurrent Neural Networks, training on the device is not a realistic option as long processing times during network training run the risk of generating an OutOfMemoryError and make for a poor user experience.", "Recurrent Neural Networks are useful for processing time series data or other sequentially fed data like video.", "Bidirectional LSTM recurrent net, based on Graves: Supervised Sequence Labelling with Recurrent Neural Networks  http://www.cs.toronto.edu/~graves/phd.pdf", "LSTM recurrent net, based on Graves: Supervised Sequence Labelling with Recurrent Neural Networks  http://www.cs.toronto.edu/~graves/phd.pdf"]}, {"name": "Nikko Strom", "time": 2, "sents": ["DL4J's asynchronous SGD implementation is based on the  Strom 2015 neural network training paper  by Nikko Strom, with some modifications.", "Here are a few more perks were added to original algorithm proposed by Nikko Strom:"]}, {"name": "Spark Data Prepration", "time": 1, "sents": ["Spark Data Prepration: How-To Guides"]}, {"name": "How-To Guides", "time": 1, "sents": ["Spark Data Prepration: How-To Guides"]}, {"name": "Understanding Scope Panic Exceptions", "time": 1, "sents": ["Understanding Scope Panic Exceptions"]}, {"name": "LSTM RNN", "time": 1, "sents": ["(c) and (d) are optional, though are recommended to get optimal performance - NVIDIA's cuDNN library is able to significantly speed up training for many layers, such as convolutional layers (ConvolutionLayer, SubsamplingLayer, BatchNormalization, etc) and LSTM RNN layers."]}, {"name": "Multi-Layer Perceptron", "time": 1, "sents": ["This is an example of a Multi-Layer Perceptron training on the Mnist data set of handwritten digits."]}, {"name": "Perform ROC", "time": 4, "sents": ["Perform ROC analysis/evaluation on the given DataSet in a distributed manner, using the specified number of steps and minibatch size", "Perform ROC analysis/evaluation (for the multi-class case, using {- link ROCMultiClass} on the given DataSet in a distributed manner", "Perform ROC analysis/evaluation on the given DataSet in a distributed manner, using the default number of threshold steps ({- link #DEFAULT_ROC_THRESHOLD_STEPS}) and the default minibatch size ({- link #DEFAULT_EVAL_SCORE_BATCH_SIZE})", "Perform ROC analysis/evaluation on the given DataSet in a distributed manner"]}, {"name": "Real-World Use Cases", "time": 1, "sents": ["Guideline 4: Focus on Real-World Use Cases - And Run a Range of Sizes"]}, {"name": "Keras ZeroPadding", "time": 3, "sents": ["Imports a Keras ZeroPadding 2D layer.", "Imports a Keras ZeroPadding 3D layer.", "Imports a Keras ZeroPadding 1D layer."]}, {"name": "Android Gradle", "time": 1, "sents": ["In order to force ProGuard to use a version of other than the Android Gradle default, you can include this in the buildscript of   file:"]}, {"name": "DL4J Keras", "time": 1, "sents": ["DL4J Keras model import is backend agnostic."]}, {"name": "Load Keras", "time": 3, "sents": ["Load Keras (Functional API) Model for which the configuration and weights were saved separately using calls to model.to_json() and model.save_weights(\u2026).", "Load Keras (Functional API) Model for which the configuration was saved separately using calls to model.to_json() and model.save_weights(\u2026).", "Load Keras (Functional API) Model saved using model.save_model(\u2026)."]}, {"name": "Functional API", "time": 6, "sents": ["Load Keras (Functional API) Model for which the configuration and weights were saved separately using calls to model.to_json() and model.save_weights(\u2026).", "Load Keras (Functional API) Model for which the configuration was saved separately using calls to model.to_json() and model.save_weights(\u2026).", "Load Keras (Functional API) Model saved using model.save_model(\u2026).", "Build ComputationGraph from Keras (Functional API) Model or Sequential model configuration.", "(Not recommended) Constructor for (Functional API) Model from model configuration (JSON or YAML), training configuration (JSON), weights, and \"training mode\" boolean indicator.", "(Recommended) Builder-pattern constructor for (Functional API) Model."]}, {"name": "USERS USE RELEASES MAVEN CENTRAL PER QUICK START GUIDE", "time": 1, "sents": ["NOTE: MOST USERS SHOULD USE THE RELEASES ON MAVEN CENTRAL AS PER THE QUICK START GUIDE, AND NOT BUILD FROM SOURCE"]}, {"name": "BUILD SOURCE", "time": 1, "sents": ["NOTE: MOST USERS SHOULD USE THE RELEASES ON MAVEN CENTRAL AS PER THE QUICK START GUIDE, AND NOT BUILD FROM SOURCE"]}, {"name": "Comma Seperated Values", "time": 1, "sents": ["If your data is in CSV (Comma Seperated Values) format stored in flat files that must be converted to numeric and ingested, or your data is a directory structure of labelled images then DataVec is the tool to help you organize that data for use in DeepLearning4J."]}, {"name": "Within IntelliJ", "time": 1, "sents": ["Within IntelliJ, you will need to choose the first Deeplearning4j example you're going to run."]}, {"name": "Simple IterationListener", "time": 1, "sents": ["Simple IterationListener that tracks time spend on training per iteration."]}, {"name": "Earth System Research Laboratory", "time": 2, "sents": ["The raw data was taken from the Earth System Research Laboratory (https://www.esrl.noaa.gov/psd/) and preprocessed into CSV files.", "The raw data was taken from the Earth System Research Laboratory (https://www.esrl.noaa.gov/psd/) and preprocessed into CSV file."]}, {"name": "Recurrent Neural Network", "time": 2, "sents": ["This sentiment analysis example classifies sentiment as positive or negative using word vectors and a Recurrent Neural Network.", "Regression with an LSTM (Long Short Term Memory) Recurrent Neural Network."]}, {"name": "Triplet Embedding", "time": 3, "sents": ["This is useful for cases such as Triplet Embedding, where embeddings can be separated and run through subsequent layers.", "This is useful for cases such as Triplet Embedding, where shared parameters are not supported by the network.", "For example, in Triplet Embedding you can input an anchor and a pos/neg class and use two parallel L2 vertices to calculate two real numbers which can be fed into a LossLayer to calculate TripletLoss."]}, {"name": "Composite DataSetPreProcessor", "time": 1, "sents": ["A simple Composite DataSetPreProcessor - allows you to apply multiple DataSetPreProcessors sequentially on the one DataSet, in the order they are passed to the constructor"]}, {"name": "Maven Five Minutes", "time": 1, "sents": ["Maven In Five Minutes"]}, {"name": "Twitter API", "time": 1, "sents": ["So bits of text (a document) can come from a file system, the Twitter API or Hadoop."]}, {"name": "Keras Cropping", "time": 3, "sents": ["Imports a Keras Cropping 3D layer.", "Imports a Keras Cropping 1D layer.", "Imports a Keras Cropping 2D layer."]}, {"name": "Get DL4J DropoutLayer", "time": 4, "sents": ["Get DL4J DropoutLayer with spatial dropout.", "Get DL4J DropoutLayer with Alpha dropout.", "Get DL4J DropoutLayer with Gaussian dropout.", "Get DL4J DropoutLayer."]}, {"name": "ND4J CUDA", "time": 1, "sents": ["When running on GPUs, there are a few components: (a) The ND4J CUDA backend (nd4j-cuda-x.x dependency) (b) The CUDA toolkit (c) The Deeplearning4j CUDA dependency to gain cuDNN support (deeplearning4j-cuda-x.x) (d) The cuDNN library files"]}, {"name": "Deeplearning4j CUDA", "time": 1, "sents": ["When running on GPUs, there are a few components: (a) The ND4J CUDA backend (nd4j-cuda-x.x dependency) (b) The CUDA toolkit (c) The Deeplearning4j CUDA dependency to gain cuDNN support (deeplearning4j-cuda-x.x) (d) The cuDNN library files"]}, {"name": "Using DataVec", "time": 1, "sents": ["Using DataVec's   class we define the schema of the data and their columns."]}, {"name": "Variational Autoencoder", "time": 1, "sents": ["Variational Autoencoder layer"]}, {"name": "Spark Programming Guide", "time": 1, "sents": ["For an explanation of these, see the  Spark Programming Guide ."]}, {"name": "Deeplearning4j UI", "time": 1, "sents": ["Step 1: Add the Deeplearning4j UI dependency to your project."]}, {"name": "Multi-angle Imaging SpectroRadiometer", "time": 1, "sents": ["The data is from NASA's Multi-angle Imaging SpectroRadiometer (MISR) which was launched in 1999."]}, {"name": "Apache Unstructured Information Management Architecture", "time": 1, "sents": ["Deeplearning4j's NLP relies on  ClearTK , an open-source machine learning and natural language processing framework for the Apache  Unstructured Information Management Architecture , or UIMA."]}, {"name": "CUDA GPUs", "time": 2, "sents": ["For DL4J, the only requirement for CUDA GPUs is to use the appropriate backend, with the appropriate NVIDIA libraries either installed on each node, or provided in the uber-JAR (see  Spark how-to guide  for more details).", "When training on CUDA GPUs, there are a couple of possible cases when adding CUDA dependencies:"]}, {"name": "Load Keras Sequential", "time": 3, "sents": ["Load Keras Sequential model saved using model.save_model(\u2026).", "Load Keras Sequential model for which the configuration was saved separately using calls to model.to_json() and model.save_weights(\u2026).", "Load Keras Sequential model for which the configuration and weights were saved separately using calls to model.to_json() and model.save_weights(\u2026)."]}, {"name": "D4j Workspace", "time": 1, "sents": ["D4j Workspace allows for memory to be preallocated before a try / catch block and reused over in over within that block."]}, {"name": "Area ROC Curve Utilizes", "time": 2, "sents": ["Calculate the AUROC - Area Under ROC Curve  Utilizes trapezoidal integration internally", "Calculate the AUC - Area Under ROC Curve  Utilizes trapezoidal integration internally"]}, {"name": "Neural Architecture Search Network", "time": 1, "sents": ["NASNet refers to Neural Architecture Search Network, a family of models that were designed automatically by learning the model architectures directly on the dataset of interest."]}, {"name": "Reduction Operations", "time": 1, "sents": ["Reduction Operations (sum, etc) ; Note that these operations operate on the entire array."]}, {"name": "Recurrent Neural Network Loss Layer", "time": 1, "sents": ["Recurrent Neural Network Loss Layer."]}, {"name": "ImageNet Classification", "time": 1, "sents": ["Dl4j's AlexNet model interpretation based on the original paper ImageNet Classification with Deep Convolutional Neural Networks and the imagenetExample code referenced."]}, {"name": "Deep Convolutional Neural Networks", "time": 1, "sents": ["Dl4j's AlexNet model interpretation based on the original paper ImageNet Classification with Deep Convolutional Neural Networks and the imagenetExample code referenced."]}, {"name": "Map Keras", "time": 1, "sents": ["Map Keras pooling layers to DL4J pooling types."]}, {"name": "Java VM", "time": 1, "sents": ["IJ starts a Java VM for you with the configurations you specify."]}, {"name": "Global Vectors", "time": 1, "sents": ["Global Vectors for Word Representation are useful for detecting relationships between words."]}, {"name": "Word Representation", "time": 1, "sents": ["Global Vectors for Word Representation are useful for detecting relationships between words."]}, {"name": "JavaCPP Presets", "time": 1, "sents": ["Alternatively, in the case of CUDA 9.2, cuDNN comes bundled with the \"redist\" package of the  JavaCPP Presets for CUDA ."]}, {"name": "PLEASE NOTE", "time": 10, "sents": ["PLEASE NOTE: This only works if number of features/labels/masks is 1", "PLEASE NOTE: Never use that option in production environment.", "PLEASE NOTE: You can't use Test iterator twice in a row.", "PLEASE NOTE: This iterator ALWAYS returns FALSE", "PLEASE NOTE : This configuration assumes that you have UDP port 40123 open on ALL nodes within your cluster.", "PLEASE NOTE: This method is NOT implemented", "PLEASE NOTE: All timers treat time values as milliseconds.", "PLEASE NOTE: File should be model file saved earlier with ModelSerializer", "PLEASE NOTE: You can't use this iterator, if underlying iterator uses randomization/shuffle between epochs.", "PLEASE NOTE: Do not use it in production environment."]}, {"name": "Mac OS X", "time": 1, "sents": ["The easiest way is to place it alongside other libraries from CUDA in the default directory (  on Linux,   on Mac OS X, and  ,  , or   on Windows)."]}, {"name": "DL4J SameDiffLambda", "time": 1, "sents": ["Wraps a DL4J SameDiffLambda into a KerasLayer"]}, {"name": "Edit Configurations", "time": 1, "sents": ["To tell DL4J to ignore those, you have to add the following as a VM parameter (Run -> Edit Configurations -> VM Options in IntelliJ):"]}, {"name": "VM Options", "time": 1, "sents": ["To tell DL4J to ignore those, you have to add the following as a VM parameter (Run -> Edit Configurations -> VM Options in IntelliJ):"]}, {"name": "Deeplearning4j Getting Started", "time": 1, "sents": ["For a longer and more detailed version of this guide, please visiting the Deeplearning4j  Getting Started  guide."]}, {"name": "MapFile Locally", "time": 1, "sents": ["Step 1: Create a MapFile Locally  In the following example, a CSVRecordReader will be used, but any other RecordReader could be used in its place:"]}, {"name": "Run Multiple Iterations", "time": 1, "sents": ["Guideline 2: Run Multiple Iterations of All Benchmarks"]}, {"name": "Notice ND4J", "time": 1, "sents": ["Notice ND4J code mirrors the equation in that nd * nd2 is row vector times column vector."]}, {"name": "Using DL4J", "time": 1, "sents": ["Using DL4J's early stopping functionality requires you to provide a number of configuration options:"]}, {"name": "Since Spark", "time": 1, "sents": ["Since Spark is unaware of the updates send via Aeron the RDD lineage tracks back to the initial parameter and optimizer state."]}, {"name": "Android Studio", "time": 5, "sents": ["In this tutorial, you saw how easy it is to create and train a neural network using the Deeplearning4J library in an Android Studio project.", "Starting with Android Studio 3.0, annotationProcessors need to be defined as well, requiring dependencies for -x86 or -arm processors.", "Starting with Android Studio 3.0, annotationProcessors need to be defined as well, thus dependencies for either -x86 or -arm processors should be included, depending on your device, if you are working in Android Studio 3.0 or later.", "Starting with Android Studio 3.0, annotationProcessors need to be defined as well, thus dependencies for either -x86 or -arm processors should be included, depending on your device, if you are working in Android Studio 3.0 or later.", "Android Studio 3.0 introduced new Gradle, now annotationProcessors should be defined too If you are using it, add following code to gradle dependencies:"]}, {"name": "Get DL4J RepeatVector", "time": 1, "sents": ["Get DL4J RepeatVector."]}, {"name": "Keras Pooling", "time": 1, "sents": ["Imports a Keras Pooling layer as a DL4J Subsampling layer."]}, {"name": "DL4J Subsampling", "time": 3, "sents": ["Imports a Keras Pooling layer as a DL4J Subsampling layer.", "Imports a Keras 2D Pooling layer as a DL4J Subsampling layer.", "Imports a Keras 1D Pooling layer as a DL4J Subsampling layer."]}, {"name": "False Positive FN", "time": 1, "sents": ["Calculate the F1 score  F1 score is defined as:  TP: true positive  FP: False Positive  FN: False Negative  F1 score: 2 TP / (2TP + FP + FN)    Note: value returned will differ depending on number of classes and settings."]}, {"name": "False Negative F1", "time": 1, "sents": ["Calculate the F1 score  F1 score is defined as:  TP: true positive  FP: False Positive  FN: False Negative  F1 score: 2 TP / (2TP + FP + FN)    Note: value returned will differ depending on number of classes and settings."]}, {"name": "Configuring Spark", "time": 1, "sents": ["Configuring Spark locality settings is an optional configuration option that can improve training performance."]}, {"name": "Converts String", "time": 2, "sents": ["Converts String column into a bag-of-words (BOW) represented as an NDArray of \"counts.\"", "Converts String column into a sparse bag-of-words (BOW) represented as an NDArray of indices."]}, {"name": "Google News", "time": 3, "sents": ["This model was trained on the Google News vocab, which you can  import  and play with.", "It comes to the Google News documents as a blank slate, and by the end of training, it can compute complex analogies that mean something to humans.", "And the most popular model used so far is Google News model."]}, {"name": "VALUE INDEX", "time": 2, "sents": ["LABEL1,LABEL2,\u2026 INDEX:VALUE INDEX:VALUE \u2026", "LABEL INDEX:VALUE INDEX:VALUE \u2026"]}, {"name": "Deeplearning4j Evaluation Page", "time": 1, "sents": ["For basic information on evaluation, see the  Deeplearning4j Evaluation Page"]}, {"name": "Evaluation Class", "time": 4, "sents": ["In DL4J the Evaluation Class and variants of the Evaluation Class are available to evaluate your model's performance.", "In DL4J the Evaluation Class and variants of the Evaluation Class are available to evaluate your model's performance.", "Additionally the Evaluation Class can also calculate and return the following values:", "This section covers basic usage of the Evaluation Class."]}, {"name": "Scalable Distributed DNN Training", "time": 1, "sents": ["For more details on the thresholding approach, see  Strom, 2015 - Scalable Distributed DNN Training using Commodity GPU Cloud Computing  and  Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks ."]}, {"name": "Commodity GPU Cloud Computing", "time": 1, "sents": ["For more details on the thresholding approach, see  Strom, 2015 - Scalable Distributed DNN Training using Commodity GPU Cloud Computing  and  Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks ."]}, {"name": "Distributed Deep Learning", "time": 1, "sents": ["For more details on the thresholding approach, see  Strom, 2015 - Scalable Distributed DNN Training using Commodity GPU Cloud Computing  and  Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks ."]}, {"name": "Distributed Training", "time": 1, "sents": ["For more details on the thresholding approach, see  Strom, 2015 - Scalable Distributed DNN Training using Commodity GPU Cloud Computing  and  Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks ."]}, {"name": "Arbiter UI", "time": 1, "sents": ["This example also goes through setting up the Arbiter UI."]}, {"name": "ND4J Workspaces", "time": 1, "sents": ["More information concerning ND4J Workspaces can be found  here ."]}, {"name": "Neural Network", "time": 8, "sents": ["Reading raw data and transforming it into a DataSet object for your Neural Network is often the first step toward training that network.", "As an alternative, the Neural Network can be trained on the desktop, saved via ModelSerializer, and then loaded as a pre-trained model in the application.", "If your Neural Network is throwing nan's then the solution is to retune your network to avoid the very small gradients.", "This TrainingListener implementation provides a way to \"sleep\" during specific Neural Network training phases.", "Demonstrates saving and loading a Neural Network built with the class MultiLayerNetwork.", "Once you need to pass data into a Neural Network, you typically use RecordReaderDataSetIterator.", "Why is my Neural Network throwing nan values?", "When training or deploying a Neural Network it is useful to know the accuracy of your model."]}, {"name": "YARN GPU", "time": 1, "sents": ["For recent versions of YARN, some additional configuration may be required in some cases - see the  YARN GPU documentation  for more details."]}, {"name": "Mismatched Library Versions", "time": 1, "sents": ["Step 4: Check for Mismatched Library Versions"]}, {"name": "Hadoop FS", "time": 1, "sents": ["Step 2: Load and Train on a Cluster  The saved DataSet objects can then be copied to the cluster or network file storage (for example, using Hadoop FS utilities on a Hadoop cluster), and used as follows:"]}, {"name": "Android Application", "time": 3, "sents": ["This tutorial will cover the use of a trained neural network in an Android Application, the handling of user generated images, and the output of the results to the UI from a background thread.", "This tutorial provides a basic framework for image recognition in an Android Application using a DL4J neural network.", "The example below illustrates the use of a Workspace for memory allocation in the AsyncTask of and Android Application."]}, {"name": "Kenny Helsens", "time": 1, "sents": ["Kenny Helsens, a data scientist based in Belgium,  applied Deeplearning4j's implementation of Word2vec  to the NCBI's Online Mendelian Inheritance In Man (OMIM) database."]}, {"name": "Online Mendelian Inheritance Man", "time": 1, "sents": ["Kenny Helsens, a data scientist based in Belgium,  applied Deeplearning4j's implementation of Word2vec  to the NCBI's Online Mendelian Inheritance In Man (OMIM) database."]}, {"name": "Keras Model", "time": 2, "sents": ["Build a ComputationGraph from this Keras Model configuration and (optionally) import weights.", "Build a ComputationGraph from this Keras Model configuration and import weights."]}, {"name": "Every Maven", "time": 1, "sents": ["Every Maven project has a POM file."]}, {"name": "Spark RDDs", "time": 1, "sents": ["All DataVec transform operations use Spark RDDs."]}, {"name": "Using Deeplearning4j", "time": 3, "sents": ["Using Deeplearning4j, you will learn how to train embeddings for facial recognition and transfer parameters to a new network that uses the embeddings for feed forward.", "For configuring cuDNN on a single node, see  Using Deeplearning4j with CuDNN", "Using Deeplearning4j, DataVec, and some custom code you will learn how to cluster large amounts of AIS data."]}, {"name": "Java Virtual Machine", "time": 3, "sents": ["\"Off-heap\" means that the memory is allocated outside of the JVM (Java Virtual Machine) and hence isn't managed by the JVM's garbage collection (GC).", "While Deeplearning4j is written in Java, the Java Virtual Machine (JVM) lets you import and share code in other JVM languages.", "Physically, the data that backs an INDArray is stored off-heap: that is, it is stored outside of the Java Virtual Machine (JVM)."]}, {"name": "DL4J Examples", "time": 1, "sents": ["Otherwise,  skip to  DL4J Examples ."]}, {"name": "Element-Wise Operations", "time": 1, "sents": ["Element-Wise Operations : Note: there are copy (add, mul, etc) and in-place (addi, muli) operations."]}, {"name": "N ROC", "time": 1, "sents": ["In practice, this means for N classes, we get N ROC curves."]}, {"name": "Get DL4J SeparableConvolution2D", "time": 1, "sents": ["Get DL4J SeparableConvolution2D."]}, {"name": "Math Stackexchange", "time": 1, "sents": ["Most math and programming questions can be answered by Googling and searching sites like  Stackoverflow  and  Math Stackexchange ."]}, {"name": "DL4J Subsampling3D", "time": 1, "sents": ["Imports a Keras 3D Pooling layer as a DL4J Subsampling3D layer."]}, {"name": "Multilayer Network", "time": 1, "sents": ["Multilayer Network to tweak for transfer learning"]}, {"name": "Spark Interpreter", "time": 2, "sents": ["The easiest solution is to add the appropriate Maven dependencies to the included Spark Interpreter.", "Once you have located the Spark Interpreter, you will need to add the following Maven library references:"]}, {"name": "Imports Reshape", "time": 1, "sents": ["Imports Reshape layer from Keras"]}, {"name": "UDP Broadcast", "time": 1, "sents": ["UDP Broadcast transfers should be faster, but for training performance, the difference should not be noticeable (except perhaps for very small workloads)."]}, {"name": "Pay Careful Attention", "time": 1, "sents": ["Guideline 3: Pay Careful Attention to What You Are Benchmarking"]}, {"name": "See ROCBinary JavaDoc", "time": 2, "sents": ["See  ROCBinary JavaDoc", "See  ROCBinary JavaDoc  is used to evaluate Binary Classifiers."]}, {"name": "Hello World", "time": 1, "sents": ["MNIST is the \"Hello World\" of deep learning."]}, {"name": "Java Development Kit", "time": 1, "sents": ["If you don't have Java 1.7 or later, download the current  Java Development Kit (JDK) here ."]}, {"name": "Using RNNs", "time": 1, "sents": ["It does that by keeping the values in several instances of  INDArray : one for the features of your examples, one for the labels and two additional ones for masking, if you are using timeseries data (see  Using RNNs / Masking  for more information)."]}, {"name": "See RegressionEvaluation JavaDoc", "time": 1, "sents": ["See  RegressionEvaluation JavaDoc"]}, {"name": "Keras Upsampling1D", "time": 1, "sents": ["Keras Upsampling1D layer support"]}, {"name": "Hadoop Map File", "time": 1, "sents": ["Now that we've saved our dataset to a Hadoop Map File, we need to set up a   and iterator that will read our saved sequences and feed them to our autoencoder."]}, {"name": "Sergey Zagoruyko", "time": 1, "sents": ["Also supports a special preProcessor used to normalize the dataset based on Sergey Zagoruyko example  https://github.com/szagoruyko/cifar.torch"]}, {"name": "Shared Memory", "time": 1, "sents": ["Aeron is a high performance messaging system that can run over UDP, Infiniband or Shared Memory."]}, {"name": "Marine Automatic Identification System", "time": 1, "sents": ["Marine  Automatic Identification System (AIS)  is an open system for marine broadcasting of positions."]}, {"name": "Average MSE", "time": 1, "sents": ["Average MSE across all columns"]}, {"name": "Make Reproducible", "time": 1, "sents": ["Guideline 6: Make It Reproducible"]}, {"name": "Visual Geometry Group", "time": 1, "sents": ["Oxford's Visual Geometry Group published  Deep Face Recognition ."]}, {"name": "Deep Face Recognition", "time": 4, "sents": ["Oxford's Visual Geometry Group published  Deep Face Recognition .", "VGG-16, from Very Deep Convolutional Networks for Large-Scale Image Recognition  https://arxiv.org/abs/1409.1556    Deep Face Recognition   http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf", "A Discriminative Feature Learning Approach for Deep Face Recognition  introduced center loss, a promising technique that added an  intraclass  component to a training loss function.", "Note that the  Deep Face Recognition  paper has a comparison of previous papers, and one key factor in FaceNet is the number of images used to train the network: 200 million."]}, {"name": "Imports Keras", "time": 1, "sents": ["Imports Keras masking layers."]}, {"name": "Data Denoising", "time": 1, "sents": ["| | | | |\u2014|\u2014|\u2014| | Data Denoising  |   |  Source  | | Dimensionality Reduction  |   |  Source  |"]}, {"name": "Dimensionality Reduction", "time": 1, "sents": ["| | | | |\u2014|\u2014|\u2014| | Data Denoising  |   |  Source  | | Dimensionality Reduction  |   |  Source  |"]}, {"name": "Skymind Intelligence Layer", "time": 1, "sents": ["You can also download a  free version of the Skymind Intelligence Layer , which supports Python, Java and Scala machine-learning and data science tools."]}, {"name": "Average R2", "time": 1, "sents": ["Average R2 across all columns"]}, {"name": "Build ComputationGraph", "time": 1, "sents": ["Build ComputationGraph from Keras (Functional API) Model or Sequential model configuration."]}, {"name": "Deeplearning4j Spark", "time": 1, "sents": ["This module is required for both development and execution of Deeplearning4j Spark jobs."]}, {"name": "DL4J Bidirectional", "time": 1, "sents": ["Builds a DL4J Bidirectional layer from a Keras Bidirectional layer wrapper"]}, {"name": "Keras Bidirectional", "time": 1, "sents": ["Builds a DL4J Bidirectional layer from a Keras Bidirectional layer wrapper"]}, {"name": "Stanford CoreNLP", "time": 1, "sents": ["Although not designed to be comparable to tools such as Stanford CoreNLP or NLTK, deepLearning4J does include some core text processing tools that are described here."]}, {"name": "Cascading Style Sheets", "time": 1, "sents": ["Cascading Style Sheets (CSS) can control the table's appearance by defining the empty-space, actual-count-header, predicted-class-header, and count-element classes."]}, {"name": "Sadat Anwar", "time": 1, "sents": ["Created by Sadat Anwar on 3/26/16."]}, {"name": "Get DL4J MaskZeroLayer", "time": 1, "sents": ["Get DL4J MaskZeroLayer."]}, {"name": "Evaluation Classes", "time": 1, "sents": ["Evaluation Classes useful for Multi-Task Network"]}, {"name": "Multi-Task Network", "time": 1, "sents": ["Evaluation Classes useful for Multi-Task Network"]}, {"name": "Creating ComputationGraphSpace", "time": 1, "sents": ["Creating ComputationGraphSpace is very similar to MultiLayerSpace."]}, {"name": "Many ND4J", "time": 1, "sents": ["Many ND4J ops are overloaded, meaning methods sharing a common name have different argument lists."]}, {"name": "Unified Embedding", "time": 1, "sents": ["In 2015, Google researchers published  FaceNet: A Unified Embedding for Face Recognition and Clustering , which set a new record for accuracy of 99.63% on the  LFW dataset ."]}, {"name": "Face Recognition", "time": 1, "sents": ["In 2015, Google researchers published  FaceNet: A Unified Embedding for Face Recognition and Clustering , which set a new record for accuracy of 99.63% on the  LFW dataset ."]}, {"name": "Detailed API", "time": 1, "sents": ["Detailed API docs for all libraries including DL4J, ND4J, DataVec, and Arbiter."]}, {"name": "Replaces String", "time": 1, "sents": ["Replaces String values that match regular expressions."]}, {"name": "Receiver Operating Characteristic", "time": 5, "sents": ["You can perform basic evaluation and get metrics such as precision and accuracy, or use a Receiver Operating Characteristic (ROC).", "ROC (Receiver Operating Characteristic) is another commonly used evaluation metric for the evaluation of classifiers.", "ROC (Receiver Operating Characteristic) for multi-class classifiers.", "ROC (Receiver Operating Characteristic) for multi-task binary classifiers.", "ROC (Receiver Operating Characteristic) for binary classifiers."]}, {"name": "Scala API", "time": 1, "sents": ["If you want to work on ScalNet, the Scala API, or on certain modules such as the DL4J UI, you will need to ensure your IDE has Scala support installed and available to you."]}, {"name": "DL4J UI", "time": 3, "sents": ["If you want to work on ScalNet, the Scala API, or on certain modules such as the DL4J UI, you will need to ensure your IDE has Scala support installed and available to you.", "A possible exception that can occur with the DL4J UI is the following:", "The DL4J UI can be used with Spark."]}, {"name": "Skymind Docker Hub", "time": 1, "sents": ["Download the latest release from the  Skymind Docker Hub ."]}, {"name": "Prepare Network", "time": 1, "sents": ["Step 2: Prepare Your Network"]}, {"name": "Getting Parts", "time": 1, "sents": ["Getting Parts of a Larger NDArray : Note: all of these methods return"]}, {"name": "Larger NDArray", "time": 1, "sents": ["Getting Parts of a Larger NDArray : Note: all of these methods return"]}, {"name": "Pearson Correlation Coefficient", "time": 1, "sents": ["Pearson Correlation Coefficient for samples"]}, {"name": "High Level Configuration", "time": 2, "sents": ["The pattern goes like this: [High Level Configuration] -> [Configure Layers] -> [Pretraining and Backprop Configuration] -> [Build Configuration]", "- High Level Configuration"]}, {"name": "Configure Layers", "time": 1, "sents": ["The pattern goes like this: [High Level Configuration] -> [Configure Layers] -> [Pretraining and Backprop Configuration] -> [Build Configuration]"]}, {"name": "Backprop Configuration", "time": 2, "sents": ["The pattern goes like this: [High Level Configuration] -> [Configure Layers] -> [Pretraining and Backprop Configuration] -> [Build Configuration]", "- Pretraining and Backprop Configuration"]}, {"name": "Build Configuration", "time": 1, "sents": ["The pattern goes like this: [High Level Configuration] -> [Configure Layers] -> [Pretraining and Backprop Configuration] -> [Build Configuration]"]}, {"name": "JVM Garbage Collector", "time": 2, "sents": ["Workspaces allow you to reuse memory for cyclic workloads without the JVM Garbage Collector for off-heap memory tracking.", "That allows you to reuse memory for cyclic workloads without the JVM Garbage Collector for off-heap memory tracking."]}, {"name": "See MultiLayerNetwork", "time": 1, "sents": ["See  MultiLayerNetwork  and  ComputationGraph  for full API."]}, {"name": "Intel MKL", "time": 2, "sents": ["However, if Intel MKL (free versions are available  here ) is installed an available, ND4J will link with it for improved performance in many BLAS operations.", "Of all the existing architectures available for CPU, Intel MKL is currently the fastest."]}, {"name": "Tiny YOLO Reference", "time": 1, "sents": ["Tiny YOLO Reference:  https://arxiv.org/pdf/1612.08242.pdf"]}, {"name": "Functional Programming Principles", "time": 1, "sents": ["If you don't know Scala and want to learn it, Coursera has a great course named  Functional Programming Principles in Scala ."]}, {"name": "Supports CuDNN", "time": 1, "sents": ["Supports CuDNN acceleration - see <a href=\"https://deeplearning4j.org/cudnn>https://deeplearning4j.org/cudnn</a> for details"]}, {"name": "Hadoop Yarn", "time": 1, "sents": ["For more details, see the Hadoop Yarn  documentation"]}, {"name": "Ede Meijer", "time": 1, "sents": ["Created by susaneraly, Ede Meijer variance and mean Pre processor for DataSet that normalizes feature values (and optionally label values) to have 0 mean and a standard deviation of 1"]}, {"name": "Array Orders", "time": 1, "sents": ["A Note on BLAS and Array Orders"]}, {"name": "Deep Convolutional Networks", "time": 2, "sents": ["VGG-16, from Very Deep Convolutional Networks for Large-Scale Image Recognition  https://arxiv.org/abs/1409.1556    Deep Face Recognition   http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf", "VGG-19, from Very Deep Convolutional Networks for Large-Scale Image Recognition   https://arxiv.org/abs/1409.1556    ImageNet weights for this model are available and have been converted from   https://github.com/fchollet/keras/tree/1.1.2/keras/applications ."]}, {"name": "Large-Scale Image Recognition", "time": 2, "sents": ["VGG-16, from Very Deep Convolutional Networks for Large-Scale Image Recognition  https://arxiv.org/abs/1409.1556    Deep Face Recognition   http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf", "VGG-19, from Very Deep Convolutional Networks for Large-Scale Image Recognition   https://arxiv.org/abs/1409.1556    ImageNet weights for this model are available and have been converted from   https://github.com/fchollet/keras/tree/1.1.2/keras/applications ."]}, {"name": "Stack Overflow", "time": 1, "sents": ["See this  Stack Overflow discussion  for a discussion of potential dependency issues."]}, {"name": "Apache Camel", "time": 1, "sents": ["Deeplearning4j works with a lot of different data types, such as images, CSV, ARFF, plain text and, with  Apache Camel   integration , pretty much any other data type you can think of."]}, {"name": "Different ROC", "time": 1, "sents": ["Different ROC types (ROC, ROCBinary and ROCMultiClass) are supported."]}, {"name": "Get LSTM", "time": 2, "sents": ["Get LSTM gate activation function from Keras layer configuration.", "Get LSTM forget gate bias initialization from Keras layer configuration."]}, {"name": "Binary Classifiers", "time": 1, "sents": ["See  ROCBinary JavaDoc  is used to evaluate Binary Classifiers."]}, {"name": "CSV Sequence Record Reader", "time": 1, "sents": ["CSV Sequence Record Reader This reader is intended to read sequences of data in CSV format, where each sequence is defined in its own file (and there are multiple files) Each line in the file represents one time step"]}, {"name": "Matt Zeiler", "time": 1, "sents": ["See the paper by Matt Zeiler for details:  http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf"]}, {"name": "DL4J API", "time": 1, "sents": ["Step-by-step tutorials for learning concepts in deep learning while using the DL4J API."]}, {"name": "PCIe/NVLink P2P", "time": 1, "sents": ["The best results are to be expected on boxes where PCIe/NVLink P2P connectivity between devices is available."]}, {"name": "Get DL4J SpaceToDepth", "time": 1, "sents": ["Get DL4J SpaceToDepth layer."]}, {"name": "Maven Shade", "time": 2, "sents": ["The recommended solution (for Maven) is to use the Maven Shade plugin to produce an uber-jar, configured as follows:", "Note also that this Maven Shade approach is configured for DL4J's examples repository."]}, {"name": "Tomas Mikolov", "time": 1, "sents": ["Word2vec is  a method of computing vector representations of words  introduced by a team of researchers at Google led by Tomas Mikolov."]}, {"name": "See EvaluationBinary JavaDoc", "time": 1, "sents": ["See  EvaluationBinary JavaDoc"]}, {"name": "DL4J Spark", "time": 2, "sents": ["DL4J Spark training supports the ability to load data serialized in a custom format.", "DL4J Spark training can also be performed using GPUs."]}, {"name": "Java API", "time": 1, "sents": ["If you prefer the Java API, call   on a  ."]}, {"name": "Francois Chollet", "time": 1, "sents": ["Little-known fact: Deeplearning4j's creator, Skymind, has two of the top five  Keras contributors  on our team, making it the largest contributor to Keras after Keras creator Francois Chollet, who's at Google."]}, {"name": "Parameters Averaging", "time": 1, "sents": ["If your cluster is running Java 7, you'll either have to upgrade or use our  Parameters Averaging training mode ."]}, {"name": "DL4J Android Applications", "time": 1, "sents": ["More information on general prerequisites for building DL4J Android Applications can be found  here ."]}, {"name": "Walt Whitman", "time": 1, "sents": ["Walt Whitman weights are available for generating text from his works, adapted from   https://github.com/craigomac/InfiniteMonkeys ."]}, {"name": "Long Short Term Memory", "time": 1, "sents": ["Regression with an LSTM (Long Short Term Memory) Recurrent Neural Network."]}, {"name": "Keras Merge", "time": 1, "sents": ["Imports a Keras Merge layer as a DL4J Merge (graph) vertex."]}, {"name": "DL4J Merge", "time": 1, "sents": ["Imports a Keras Merge layer as a DL4J Merge (graph) vertex."]}, {"name": "RegressionEvaluation Class", "time": 1, "sents": ["To Evaluate a network performing regression use the RegressionEvaluation Class."]}, {"name": "DL4J Android Application", "time": 2, "sents": ["A third example DL4J Android Application can be found  here  which loads a pre-trained Mnist network and uses it to classify user drawn numbers.", "A second example DL4J Android Application which includes a user interface can be found  here ."]}, {"name": "CUDA Backend", "time": 1, "sents": ["The CUDA Backend has some additional requirements before it can be built:"]}, {"name": "Learn Python", "time": 1, "sents": ["\"Learn Python the Hard Way\" and \"Learn to Program (Ruby)\" are two great places to start."]}, {"name": "Hard Way", "time": 1, "sents": ["\"Learn Python the Hard Way\" and \"Learn to Program (Ruby)\" are two great places to start."]}, {"name": "Neural Net", "time": 3, "sents": ["The trained network is passed live onboard video and decisions based on object detection from the Neural Net determine the vehicles actions.", "Takes the complete works of Shakespeare as a sequence of characters and Trains a Neural Net to generate \"Shakespeare\" one character at a time.", "In a typical Neural Net application you use DataVec to ingest and convert the data to numeric."]}, {"name": "RMS Prop", "time": 1, "sents": ["RMS Prop updates:"]}, {"name": "Element-Wise Transforms", "time": 1, "sents": ["Element-Wise Transforms (Tanh, Sigmoid, Sin, Log etc) :"]}, {"name": "DataInputStream Unlike", "time": 2, "sents": ["Load a sequence record from the given DataInputStream Unlike {- link #next()} the internal state of the RecordReader is not modified Implementations of this method should not close the DataInputStream", "Load the record from the given DataInputStream Unlike {- link #next()} the internal state of the RecordReader is not modified Implementations of this method should not close the DataInputStream"]}, {"name": "Stochastic Neighbor Embedding", "time": 2, "sents": ["t-Distributed Stochastic Neighbor Embedding (t-SNE) is useful for data visualization.", "t-Distributed Stochastic Neighbor Embedding  (t-SNE) is a data-visualization tool created by Laurens van der Maaten at Delft University of Technology."]}, {"name": "Empirical Evaluation", "time": 1, "sents": ["Empirical Evaluation of Rectified Activations in Convolutional Network"]}, {"name": "Rectified Activations", "time": 1, "sents": ["Empirical Evaluation of Rectified Activations in Convolutional Network"]}, {"name": "Convolutional Network", "time": 1, "sents": ["Empirical Evaluation of Rectified Activations in Convolutional Network"]}, {"name": "Setting Single Values", "time": 1, "sents": ["Getting and Setting Single Values :"]}, {"name": "Creating NDArrays", "time": 1, "sents": ["Creating NDArrays :"]}, {"name": "Overview Page", "time": 2, "sents": ["Overview Page and Model Page - Using the Update: Parameter Ratio Chart", "Overview Page - Model Score vs. Iteration Chart"]}, {"name": "Model Page", "time": 5, "sents": ["Overview Page and Model Page - Using the Update: Parameter Ratio Chart", "Model Page: Layer Activations (vs. Time) Chart", "Model Page: Layer Updates Histogram", "Model Page: Parameter Learning Rates Chart", "Model Page: Layer Parameters Histogram"]}, {"name": "Parameter Ratio Chart", "time": 1, "sents": ["Overview Page and Model Page - Using the Update: Parameter Ratio Chart"]}, {"name": "Max Pumperla", "time": 1, "sents": ["author: Max Pumperla"]}, {"name": "Layer Activations", "time": 1, "sents": ["Model Page: Layer Activations (vs. Time) Chart"]}, {"name": "Use MultiLayerNetwork/ComputationGraph.fit", "time": 1, "sents": ["Use MultiLayerNetwork/ComputationGraph.fit(DataSetIterator, int numEpochs) instead"]}, {"name": "IntelliJ IDE", "time": 1, "sents": ["In the case of Deeplearning4j, you should know Java well and be comfortable with tools like the IntelliJ IDE and the automated build tool Maven."]}, {"name": "CPU RAM", "time": 3, "sents": ["We also allocate off-heap memory on the CPU RAM as well.", "When GPU RAM is less than CPU RAM, you need to monitor how much RAM is being used off-heap.", "When using GPUs, oftentimes your CPU RAM will be greater than GPU RAM."]}, {"name": "R^2 Score", "time": 1, "sents": ["Coefficient of Determination (R^2 Score)"]}, {"name": "Logistic Regression", "time": 2, "sents": ["|\u2014|\u2014|\u2014| | Logistic Regression  |   |  Source  | \u2014 The layer with x1, x2, x3, \u2026, xn is out input layer.", "|\u2014|\u2014|\u2014| | Logistic Regression  |   |  Source  |"]}, {"name": "Installing ATLAS", "time": 1, "sents": ["Installing ATLAS on OS X is a somewhat complicated and lengthy process."]}, {"name": "Spark IP", "time": 1, "sents": ["We're using netmasks for cases when Spark cluster is run on top of hadoop, or any other environment which doesn't assume Spark IP addresses announced."]}, {"name": "Performance Listener", "time": 1, "sents": ["In order to determine whether Spark will help you or not, consider using the  Performance Listener  and look at the millisecond iteration time."]}, {"name": "Keras Upsampling3D", "time": 1, "sents": ["Keras Upsampling3D layer support"]}, {"name": "Leaky RELU", "time": 1, "sents": ["Leaky RELU f(x) = max(0, x) + alpha min(0, x) alpha defaults to 0.01"]}, {"name": "Discriminative Feature Learning Approach", "time": 1, "sents": ["A Discriminative Feature Learning Approach for Deep Face Recognition  introduced center loss, a promising technique that added an  intraclass  component to a training loss function."]}, {"name": "LABEL INDEX", "time": 1, "sents": ["LABEL INDEX:VALUE INDEX:VALUE \u2026"]}, {"name": "Vectorized Learning Rate", "time": 1, "sents": ["Vectorized Learning Rate used per Connection Weight"]}, {"name": "Connection Weight", "time": 1, "sents": ["Vectorized Learning Rate used per Connection Weight"]}, {"name": "Keras Upsampling2D", "time": 1, "sents": ["Keras Upsampling2D layer support"]}, {"name": "RDDs Default", "time": 2, "sents": ["Random number generator seed, used mainly for enforcing repeatable splitting/repartitioning on RDDs Default: no seed set (i.e., random seed)", "Random number generator seed, used mainly for enforcing repeatable splitting on RDDs Default: no seed set (i.e., random seed)"]}, {"name": "Network IO", "time": 1, "sents": ["Network IO has its own price, and this algorithm does some IO as well."]}, {"name": "Java Object Serialization", "time": 1, "sents": ["Add an object to the (already existing) model file using Java Object Serialization."]}, {"name": "Arithmetic Underflow", "time": 1, "sents": ["The term for this issue is Arithmetic Underflow."]}, {"name": "Time Iteration Listener", "time": 1, "sents": ["Time Iteration Listener."]}, {"name": "Three ROC", "time": 1, "sents": ["Three ROC variants exist in DL4J:"]}, {"name": "Prepare Data", "time": 1, "sents": ["Step 1: Prepare Your Data"]}, {"name": "See Getting", "time": 1, "sents": ["See  Getting and Setting Parts of NDArrays  for details on this."]}, {"name": "Setting Parts", "time": 1, "sents": ["See  Getting and Setting Parts of NDArrays  for details on this."]}, {"name": "Stochastic Gradient Descent", "time": 1, "sents": ["Stochastic Gradient Descent, the most common learning algorithm in deep learning, relies on   (the weights in hidden layers) and   (the learning rate)."]}, {"name": "CentOS Enter", "time": 1, "sents": ["CentOS  Enter the following in your terminal (or ssh session) as a root user:"]}, {"name": "Word2Vec Use Memory", "time": 1, "sents": ["Q: How does Word2Vec Use Memory?"]}, {"name": "One GravesLSTM", "time": 1, "sents": ["One GravesLSTM layer and two RnnOutputLayers will be used."]}, {"name": "CUDA-enabled GPU", "time": 1, "sents": ["If you have a CUDA-enabled GPU and have  nvidia-docker  installed:"]}, {"name": "Dependency Conflict", "time": 1, "sents": ["Step 5: Once Identified, Fix the Dependency Conflict"]}, {"name": "Basic Linear Algebra Subprograms", "time": 1, "sents": ["BLAS - or Basic Linear Algebra Subprograms - refers to an interface and set of methods used for linear algebra operations."]}, {"name": "Collecting Stats", "time": 1, "sents": ["Collecting Stats for Later Offline Use"]}, {"name": "Later Offline Use", "time": 1, "sents": ["Collecting Stats for Later Offline Use"]}, {"name": "Van Gogh", "time": 1, "sents": ["Just as Van Gogh's painting of sunflowers is a two-dimensional mixture of oil on canvas that  represents  vegetable matter in a three-dimensional space in Paris in the late 1880s, so 500 numbers arranged in a vector can represent a word or group of words."]}, {"name": "Model Score", "time": 1, "sents": ["Overview Page - Model Score vs. Iteration Chart"]}, {"name": "Iteration Chart", "time": 1, "sents": ["Overview Page - Model Score vs. Iteration Chart"]}, {"name": "Get DL4J ActivationLayer", "time": 1, "sents": ["Get DL4J ActivationLayer."]}, {"name": "DEBUG First", "time": 1, "sents": ["Example: Data in format \"2016-01-01 23:59:59.001 1 DEBUG First entry message!\""]}, {"name": "Keras LSTM", "time": 1, "sents": ["Imports a Keras LSTM layer as a DL4J LSTM layer."]}, {"name": "DL4J LSTM", "time": 1, "sents": ["Imports a Keras LSTM layer as a DL4J LSTM layer."]}, {"name": "Composite MultiDataSetPreProcessor", "time": 1, "sents": ["A simple Composite MultiDataSetPreProcessor - allows you to apply multiple MultiDataSetPreProcessors sequentially on the one MultiDataSet, in the order they are passed to the constructor"]}, {"name": "Layer Updates Histogram", "time": 1, "sents": ["Model Page: Layer Updates Histogram"]}, {"name": "Curve Utilizes", "time": 1, "sents": ["Calculate the AUC - Area Under (ROC) Curve  Utilizes trapezoidal integration internally"]}, {"name": "See Geoff Hinton", "time": 1, "sents": ["See Geoff Hinton's definitive work,  A Practical Guide to Training Restricted Boltzmann Machines , for a list of all of the different probability distributions."]}, {"name": "Practical Guide", "time": 1, "sents": ["See Geoff Hinton's definitive work,  A Practical Guide to Training Restricted Boltzmann Machines , for a list of all of the different probability distributions."]}, {"name": "Training Restricted Boltzmann Machines", "time": 1, "sents": ["See Geoff Hinton's definitive work,  A Practical Guide to Training Restricted Boltzmann Machines , for a list of all of the different probability distributions."]}, {"name": "Typical Deep", "time": 1, "sents": ["Typical Deep leaning model consists of many layers between the inputs and outputs."]}, {"name": "Mapping Keras", "time": 1, "sents": ["Mapping Keras to DL4J constraints happens in  KerasConstraintUtils ."]}, {"name": "Area Curve Precision Recall Utilizes", "time": 1, "sents": ["Calculate the AUPRC - Area Under Curve Precision Recall   Utilizes trapezoidal integration internally"]}, {"name": "See Using RNNs", "time": 1, "sents": ["See  Using RNNs - Masking  for more details on masking."]}, {"name": "Training Guides", "time": 2, "sents": ["Before Training Guides", "During and After Training Guides"]}, {"name": "Tiny ImageNet", "time": 2, "sents": ["Tiny ImageNet is a subset of the ImageNet database.", "Tiny ImageNet has 200 classes, each consisting of 500 training images."]}, {"name": "Schema Transformation", "time": 1, "sents": ["If however your data has non-numeric fields such as strings representing boolean (T/F) or strings for labels then a Schema Transformation will be required."]}, {"name": "Keras Flatten", "time": 1, "sents": ["Imports a Keras Flatten layer as a DL4J {Cnn,Rnn}ToFeedForwardInputPreProcessor."]}, {"name": "EMNIST DataSetIterator", "time": 1, "sents": ["EMNIST DataSetIterator"]}, {"name": "OpenFace NN4.Small2", "time": 1, "sents": ["The network will be built using   (Inception-type networks require multiple nodes) via the  OpenFace NN4.Small2  variant, which is a hand-tuned, parameter-minimized model of FaceNet."]}, {"name": "Auto-Encoding Variational Bayes", "time": 1, "sents": ["See: Kingma & Welling, 2013: Auto-Encoding Variational Bayes -  https://arxiv.org/abs/1312.6114"]}, {"name": "Convolutional Neural Networks", "time": 1, "sents": ["Convolutional Neural Networks are mainly used for image recognition, although they apply to sound and text as well."]}, {"name": "Get DL4J Bidirectional", "time": 1, "sents": ["Get DL4J Bidirectional layer."]}, {"name": "DataVec Transform", "time": 1, "sents": ["*note you do not need to know the internals of Spark to be succesful with DataVec Transform"]}, {"name": "IntelliJ IDEA", "time": 1, "sents": ["It is also recommended that you download and install IntelliJ IDEA, Maven, and the complete dl4j-examples directory for building and building and training neural nets on your desktop instead of android studio."]}, {"name": "Iris Data Set", "time": 1, "sents": ["IrisDataSetIterator handles traversing through the Iris Data Set."]}, {"name": "F1 Score", "time": 1, "sents": ["By default the .stats() method displays the confusion matrix entries (one per line), Accuracy, Precision, Recall and F1 Score."]}, {"name": "Average Pearson Correlation Coefficient", "time": 1, "sents": ["Average Pearson Correlation Coefficient across all columns"]}, {"name": "String Reduce", "time": 1, "sents": ["TODO: use new String Reduce functionality in DataVec?"]}, {"name": "See Deeplearning4j", "time": 1, "sents": ["See  Deeplearning4j on Spark: How To Guides  for further details."]}, {"name": "Highway Layers", "time": 1, "sents": ["For example, Highway Layers need them in two places."]}, {"name": "Linear Algebra Operations", "time": 1, "sents": ["Linear Algebra Operations :"]}, {"name": "Optimization Algorithm", "time": 1, "sents": ["Function | Details \u2014\u2014\u2014\u2014\u2014- | \u2014\u2014\u2014\u2014- seed | For keeping the network outputs reproducable during runs by initializing weights and other network randomizations through a seed learningRate | For identifying the network learning rate iterations | For identifying the number of optimization iterations optimizationAlgo | Optimization Algorithm to use for training."]}, {"name": "Geoff Hinton", "time": 1, "sents": ["(Geoff Hinton, teaching people to imagine 13-dimensional space, suggests that students first picture 3-dimensional space and then say to themselves: \"Thirteen, thirteen, thirteen.\""]}, {"name": "A. Backpropagation", "time": 1, "sents": ["A. Backpropagation involves the multiplication of very small gradients, due to limited precision when representing real numbers values very close to zero can not be represented."]}, {"name": "DL4J Suite", "time": 1, "sents": ["Arbiter is part of the DL4J Suite of Machine Learning/Deep Learning tools for the enterprise."]}, {"name": "Machine Learning/Deep Learning", "time": 1, "sents": ["Arbiter is part of the DL4J Suite of Machine Learning/Deep Learning tools for the enterprise."]}, {"name": "Real-Time Object Detection", "time": 1, "sents": ["Output (loss) layer for YOLOv2 object detection model, based on the papers: YOLO9000: Better, Faster, Stronger - Redmon & Farhadi (2016) -  https://arxiv.org/abs/1612.08242  and  You Only Look Once: Unified, Real-Time Object Detection - Redmon et al."]}, {"name": "Xth Iteration/Epoch", "time": 1, "sents": ["It can be launched every Xth Iteration/Epoch, depending on frequency and InvocationType constructor arguments"]}, {"name": "Ubuntu Assuming", "time": 2, "sents": ["Ubuntu  Assuming you are using Ubuntu, you can install OpenBLAS via:", "Ubuntu  Assuming you are using Ubuntu as your flavor of Linux and you are running as a non-root user, follow these steps to install prerequisite software:"]}, {"name": "Darknet19 Reference", "time": 1, "sents": ["Darknet19  Reference:  https://arxiv.org/pdf/1612.08242.pdf    ImageNet weights for this model are available and have been converted from  https://pjreddie.com/darknet/imagenet/  using https://github.com/allanzelener/YAD2K ."]}, {"name": "Scalable Distributed DNN Training Using Commodity GPU Cloud Computing Default", "time": 1, "sents": ["For technical details, see the paper   Scalable Distributed DNN Training Using Commodity GPU Cloud Computing    Default value: 1e-3    Note also that the threshold will be adjusted somewhat during training to avoid the updates becoming too sparse"]}, {"name": "Area Curve", "time": 2, "sents": ["Calculate the AUCPR - Area Under Curve - Precision Recall  Utilizes trapezoidal integration internally", "An   class has more built-in methods if you need to extract a confusion matrix, and other tools are also available for calculating the Area Under Curve (AUC)."]}, {"name": "Precision Recall Utilizes", "time": 1, "sents": ["Calculate the AUCPR - Area Under Curve - Precision Recall  Utilizes trapezoidal integration internally"]}, {"name": "CUDA GPU", "time": 1, "sents": ["Both (a) and (b) must be available for ND4J/DL4J to run using an available CUDA GPU run."]}, {"name": "Trained Keras", "time": 1, "sents": ["*Note : Trained Keras models (not provided by DL4J) may also be imported, using Deeplearning4j's Keras model import functionality."]}, {"name": "Imports PReLU", "time": 1, "sents": ["Imports PReLU layer from Keras"]}, {"name": "Stanford Natural Language Processing Group", "time": 1, "sents": ["The  Stanford Natural Language Processing Group  has a number of Java-based tools for tokenization, part-of-speech tagging and named-entity recognition for languages such as  Mandarin Chinese , Arabic, French, German and Spanish."]}, {"name": "Mandarin Chinese", "time": 1, "sents": ["The  Stanford Natural Language Processing Group  has a number of Java-based tools for tokenization, part-of-speech tagging and named-entity recognition for languages such as  Mandarin Chinese , Arabic, French, German and Spanish."]}, {"name": "Delft University", "time": 1, "sents": ["t-Distributed Stochastic Neighbor Embedding  (t-SNE) is a data-visualization tool created by Laurens van der Maaten at Delft University of Technology."]}, {"name": "Imports ThresholdedReLU", "time": 1, "sents": ["Imports ThresholdedReLU layer from Keras"]}, {"name": "Parameter Learning Rates Chart", "time": 1, "sents": ["Model Page: Parameter Learning Rates Chart"]}, {"name": "See DL4J", "time": 1, "sents": ["See DL4J's Spark website documentation for details."]}, {"name": "Keras RepeatVector", "time": 1, "sents": ["Imports a Keras RepeatVector layer"]}, {"name": "Typically RNN", "time": 1, "sents": ["Typically RNN's are much more effective than regular feed forward neural networks for sequential data because they can keep track of dependencies in the data over multiple time steps."]}, {"name": "Spark Cluster", "time": 1, "sents": ["DeepLearning4j supports using a Spark Cluster for network training."]}, {"name": "Average RSE", "time": 1, "sents": ["Average RSE across all columns"]}, {"name": "Computation Graph", "time": 1, "sents": ["This page describes how to build more complicated networks, using DL4J's Computation Graph functionality."]}, {"name": "Loss Function", "time": 1, "sents": ["Do you need to add a Loss Function that is not available or prebuilt yet?"]}, {"name": "Hadoop MapFile", "time": 1, "sents": ["An alternative approach is to use Hadoop MapFile and SequenceFiles, which are efficient binary storage formats."]}, {"name": "Okhotsk Seas", "time": 2, "sents": ["Recall, that the data consists of 2-dimensional temperature grids of 8 seas: Bengal, Korean, Black, Mediterranean, Arabian, Japan, Bohai, and Okhotsk Seas from 1981 to 2017.", "The data consists of 2-dimensional temperature grids of 8 seas: Bengal, Korean, Black, Mediterranean, Arabian, Japan, Bohai, and Okhotsk Seas from 1981 to 2017."]}, {"name": "Layer API", "time": 1, "sents": ["DL4J's Layer API includes the concept of a \"layer workspace manager\"."]}, {"name": "Sea Temperature Convolutional LSTM Example", "time": 1, "sents": ["This tutorial will be similar to tutorial 15 Sea Temperature Convolutional LSTM Example."]}, {"name": "Element-wise NDArray", "time": 1, "sents": ["Element-wise NDArray math operation (add, subtract, etc) on an NDArray column"]}, {"name": "Space Invaders", "time": 1, "sents": ["Deep learning algorithms have learned to play Space Invaders and Doom using reinforcement learning."]}, {"name": "DL4J Cache Mode", "time": 1, "sents": ["Some configuration options of note: (a)  Memory configuration  (b)  Workspaces and garbage collection  (c)  CuDNN  (d) DL4J Cache Mode (enable using  )"]}, {"name": "See ROCMultiClass JavaDoc", "time": 1, "sents": ["See  ROCMultiClass JavaDoc"]}, {"name": "Maven Central", "time": 1, "sents": ["The only difference is that they are served from a custom repository rather than from Maven Central."]}, {"name": "Average MAE", "time": 1, "sents": ["Average MAE across all columns"]}, {"name": "Graves LSTM", "time": 1, "sents": ["For example, feed forward neural networks are comprised of dense layers, while recurrent neural networks can include Graves LSTM (long short-term memory) layers."]}, {"name": "MEMORY_AND_DISK_SER Recommended", "time": 1, "sents": ["Why MEMORY_ONLY_SER or MEMORY_AND_DISK_SER Are Recommended"]}, {"name": "Unlike Hadamard", "time": 1, "sents": ["Unlike Hadamard products, which require that both matrices have equal rows and columns, inner products simply require that the number of columns of the first matrix equal the number of rows of the second."]}, {"name": "Gitter Live Chat", "time": 2, "sents": ["We recommend that you join our  Gitter Live Chat .", "However, IntelliJ is preferred, and using it will make finding help on  Gitter Live Chat  easier if you need it."]}, {"name": "Confusion Matrix", "time": 1, "sents": ["Display the Confusion Matrix."]}, {"name": "Create LFW", "time": 1, "sents": ["Create LFW data specific iterator"]}, {"name": "Remote UI Functionality", "time": 1, "sents": ["Using the Remote UI Functionality"]}, {"name": "Java GC", "time": 2, "sents": ["We rely on the Java GC to tell us what to collect; the Java GC points at things, and we know how to de-allocate them with JavaCPP.", "We rely on the Java GC to tell us what to collect; the Java GC points at things, and we know how to de-allocate them with JavaCPP."]}, {"name": "Support Vector Machines", "time": 1, "sents": ["Some examples of hyperparameters are 'k' in k-nearest-neighbors and the regularization parameter in Support Vector Machines."]}, {"name": "Quick Start Guide", "time": 1, "sents": ["The  Quick Start Guide  shows you how to set up Intellij and clone the repository."]}, {"name": "Mean Squared Error", "time": 1, "sents": ["Columns are Mean Squared Error, Mean Absolute Error, Root Mean Squared Error, Relative Squared Error, and R^2 Coefficient of Determination"]}, {"name": "Mean Absolute Error", "time": 1, "sents": ["Columns are Mean Squared Error, Mean Absolute Error, Root Mean Squared Error, Relative Squared Error, and R^2 Coefficient of Determination"]}, {"name": "Root Mean Squared Error", "time": 1, "sents": ["Columns are Mean Squared Error, Mean Absolute Error, Root Mean Squared Error, Relative Squared Error, and R^2 Coefficient of Determination"]}, {"name": "Relative Squared Error", "time": 1, "sents": ["Columns are Mean Squared Error, Mean Absolute Error, Root Mean Squared Error, Relative Squared Error, and R^2 Coefficient of Determination"]}, {"name": "R^2 Coefficient", "time": 1, "sents": ["Columns are Mean Squared Error, Mean Absolute Error, Root Mean Squared Error, Relative Squared Error, and R^2 Coefficient of Determination"]}, {"name": "Learning Rate Schedules", "time": 1, "sents": ["Note that (as of current master - but not 0.9.1) the dropout parameters can also be specified according to any of the schedule classes mentioned in the Learning Rate Schedules section."]}, {"name": "GPU RAM", "time": 2, "sents": ["When GPU RAM is less than CPU RAM, you need to monitor how much RAM is being used off-heap.", "When using GPUs, oftentimes your CPU RAM will be greater than GPU RAM."]}, {"name": "Andrej Karpathy", "time": 1, "sents": ["Here's an excellent  web page by Andrej Karpathy  about visualizing neural net training."]}, {"name": "DL4J Provides", "time": 1, "sents": ["DL4J Provides a user interface to visualize in your browser (in real time) the current network status and progress of training."]}, {"name": "Loss MCXENT", "time": 1, "sents": ["Loss function for the class predictions - defaults to L2 loss (i.e., sum of squared errors, as per the paper), however Loss MCXENT could also be used (which is more common for classification)."]}, {"name": "SPARK ISSUES", "time": 1, "sents": ["Q:   SPARK ISSUES  I am running the examples and having issues with the Spark based examples such as distributed training or datavec transform options."]}, {"name": "Center Loss", "time": 1, "sents": ["To see that Center Loss if already in the model configuration, you can print a string table of all layers in the network."]}, {"name": "Spark Versions", "time": 1, "sents": ["Step 2: Check your Spark Versions"]}, {"name": "Maven POM", "time": 1, "sents": ["A Maven POM would add the following:"]}, {"name": "DL4J InputPreProcessor", "time": 1, "sents": ["Gets appropriate DL4J InputPreProcessor for given InputTypes."]}, {"name": "See Visualize", "time": 1, "sents": ["See  Visualize, Monitor and Debug Network Learning  on how to interpret that data."]}, {"name": "Debug Network Learning", "time": 1, "sents": ["See  Visualize, Monitor and Debug Network Learning  on how to interpret that data."]}, {"name": "Many DataSetIterators", "time": 1, "sents": ["Many DataSetIterators do support resetting, but some don't"]}, {"name": "Google Scholar", "time": 1, "sents": ["Google Scholar keeps a running tally of the papers citing  Deeplearning4j's implementation of Word2vec here ."]}, {"name": "Deeplearning4j Early Adopters Channel", "time": 1, "sents": ["If you encounter issues while building locally, the Deeplearning4j  Early Adopters Channel  is a channel dedicated to assisting with build issues and other source problems."]}, {"name": "Elvis Costello", "time": 1, "sents": ["As Elvis Costello said: \"Writing about music is like dancing about architecture.\""]}, {"name": "Understand Hardware", "time": 1, "sents": ["Guideline 5: Understand Your Hardware"]}, {"name": "See Evaluation", "time": 1, "sents": ["See Evaluation javadoc for more details on evaluation in the binary case"]}, {"name": "Andreas Klintberg", "time": 1, "sents": ["Andreas Klintberg trained Deeplearning4j's implementation of Word2vec on Swedish, and wrote a  thorough walkthrough on Medium ."]}, {"name": "DataSet Iterator", "time": 2, "sents": ["Our training data will have 3200 examples which will be represented by a single DataSetIterator, and the testing data will have 800 examples which will be represented by a separate DataSet Iterator.", "Our training data will have 1700 examples which will be represented by a single DataSetIterator, and the testing data will have 404 examples which will be represented by a separate DataSet Iterator."]}, {"name": "YourKit Profilers", "time": 1, "sents": ["If you aren't sure if you are only measuring what you intend to measure when running DL4J or ND4J code, you can use a profiler such as VisualVM or YourKit Profilers."]}, {"name": "Negative Sampling", "time": 1, "sents": ["While Word2vec refers to a family of related algorithms, this implementation uses  Negative Sampling ."]}, {"name": "ScalarMax ScalarMin/Max", "time": 1, "sents": ["Note: only the following MathOps are supported: Add, Subtract, ScalarMin, ScalarMax  For ScalarMin/Max, the TimeUnit must be milliseconds - i.e., value must be in epoch millisecond format"]}, {"name": "Bidirectional LSTM", "time": 2, "sents": ["Bidirectional LSTM recurrent net, based on Graves: Supervised Sequence Labelling with Recurrent Neural Networks  http://www.cs.toronto.edu/~graves/phd.pdf", "Layer space for Bidirectional LSTM layers"]}, {"name": "Supervised Sequence Labelling", "time": 2, "sents": ["Bidirectional LSTM recurrent net, based on Graves: Supervised Sequence Labelling with Recurrent Neural Networks  http://www.cs.toronto.edu/~graves/phd.pdf", "LSTM recurrent net, based on Graves: Supervised Sequence Labelling with Recurrent Neural Networks  http://www.cs.toronto.edu/~graves/phd.pdf"]}, {"name": "GET STARTED DEEP LEARNING", "time": 1, "sents": ["GET STARTED WITH DEEP LEARNING"]}, {"name": "Eclipse Foundation", "time": 1, "sents": ["Deeplearning4j is  open source , written in C++, Java, Scala, and Python, and maintained by the Eclipse Foundation & community contributors."]}, {"name": "Integrated Development Environment", "time": 1, "sents": ["An Integrated Development Environment ( IDE ) allows you to work with our API and configure neural networks in a few steps."]}, {"name": "Outputs Confusion Matrix", "time": 1, "sents": ["Outputs Confusion Matrix in an HTML table."]}, {"name": "Getting Started", "time": 1, "sents": ["Follow the typical  Getting Started  instructions for Deeplearning4j, and appropriately replace versions with the SNAPSHOT version currently on the  master POM ."]}, {"name": "Reading Records", "time": 1, "sents": ["Please  read this entire page , particularly the section  Reading Records  below, before working with DataVec."]}, {"name": "General Matrix Multiplication", "time": 1, "sents": ["Some examples include 'gemm' - General Matrix Multiplication - and 'axpy', which implements  ."]}, {"name": "NVIDA GPUs", "time": 1, "sents": ["Deeplearning4j and ND4J support GPU acceleration using NVIDA GPUs."]}, {"name": "Single Layer Perceptron", "time": 1, "sents": ["This is a Single Layer Perceptron for recognizing digits."]}, {"name": "Basic Autoencoder", "time": 1, "sents": ["As you learned in the  Basic Autoencoder  tutorial, applications of autoencoders in data science include dimensionality reduction and data denoising."]}, {"name": "Smile Scala", "time": 1, "sents": ["The  Smile Scala library  has a number of clustering methods already available and we'll be using it for grouping our trajectories."]}, {"name": "Spark MLLib LabeledPoint", "time": 2, "sents": ["Fits a MultiLayerNetwork using Spark MLLib LabeledPoint instances This will convert labeled points that have continuous labels used for regression to the internal DL4J data format and train the model on that", "Fit a MultiLayerNetwork using Spark MLLib LabeledPoint instances."]}, {"name": "See Troubleshooting", "time": 1, "sents": ["See  Troubleshooting neural nets  for more information on how to improve results."]}, {"name": "SequenceMovingWindowReduceTransform Adds", "time": 1, "sents": ["SequenceMovingWindowReduceTransform Adds a new column, where the value is derived by:  (a) using a window of the last N values in a single column,  (b) Apply a reduction op on the window to calculate a new value  for example, this transformer can be used to implement a simple moving average of the last N values, or determine the minimum or maximum values in the last N time steps."]}, {"name": "JSON String", "time": 1, "sents": ["Deserialize a JSON String (created by {- link #toJson()}) to a TransformProcess"]}, {"name": "NOTE CLIENT SERVER", "time": 1, "sents": ["(NOTE THIS IS NOT THE CLIENT THIS IS YOUR SERVER - SEE BELOW FOR THE CLIENT WHICH USES: deeplearning4j-ui-model)"]}, {"name": "SEE CLIENT USES", "time": 1, "sents": ["(NOTE THIS IS NOT THE CLIENT THIS IS YOUR SERVER - SEE BELOW FOR THE CLIENT WHICH USES: deeplearning4j-ui-model)"]}, {"name": "Deep Face", "time": 1, "sents": ["Facebook's Deep Face uses nine hidden layers on what we can only presume to be an immense corpus."]}, {"name": "Collect Dependency Information", "time": 1, "sents": ["Step 1: Collect Dependency Information"]}, {"name": "Top N", "time": 1, "sents": ["Top N accuracy of the predictions so far."]}, {"name": "Average RMSE", "time": 1, "sents": ["Average RMSE across all columns"]}, {"name": "YOLOv2 Reference", "time": 1, "sents": ["YOLOv2 Reference: https://arxiv.org/pdf/1612.08242.pdf"]}, {"name": "Parametrized Rectified Linear Unit", "time": 1, "sents": ["/ Parametrized Rectified Linear Unit (PReLU)"]}, {"name": "Woldemar Voigt", "time": 1, "sents": ["Tensor was introduced to English from the German in 1915, after being coined by Woldemar Voigt in 1898."]}, {"name": "Paul Dubs", "time": 1, "sents": ["Paul Dubs' guide to maven"]}, {"name": "Keras SimpleRNN", "time": 1, "sents": ["Imports a Keras SimpleRNN layer as a DL4J SimpleRnn layer."]}, {"name": "DL4J SimpleRnn", "time": 1, "sents": ["Imports a Keras SimpleRNN layer as a DL4J SimpleRnn layer."]}, {"name": "Imports LeakyReLU", "time": 1, "sents": ["Imports LeakyReLU layer from Keras"]}, {"name": "Run Warm-Up Iterations Benchmarking", "time": 1, "sents": ["Guideline 1: Run Warm-Up Iterations Before Benchmarking"]}, {"name": "Scope Panic Exceptions", "time": 1, "sents": ["Workarounds and Fixes for Scope Panic Exceptions"]}, {"name": "Imports Permute", "time": 1, "sents": ["Imports Permute layer from Keras"]}, {"name": "Thresholded RELU", "time": 1, "sents": ["Thresholded RELU"]}, {"name": "Scalable Distributed DNN Training Using Commodity GPU Cloud Computing", "time": 1, "sents": ["SharedTrainingMaster implements distributed training of neural networks using a compressed quantized gradient (update) sharing implementation based on the Strom 2015 paper \"Scalable Distributed DNN Training Using Commodity GPU Cloud Computing\":  https://s3-us-west-2.amazonaws.com/amazon.jobs-public-documents/strom_interspeech2015.pdf ."]}, {"name": "Keras RNN", "time": 1, "sents": ["Utility functions for Keras RNN layers"]}, {"name": "Uses Writable.toString", "time": 1, "sents": ["Note:  Uses Writable.toString(), hence can potentially be applied to non-String columns"]}, {"name": "Boolean Indexing Unit Tests", "time": 1, "sents": ["Link: Boolean Indexing Unit Tests"]}, {"name": "Get DL4J DepthwiseConvolution2D", "time": 1, "sents": ["Get DL4J DepthwiseConvolution2D."]}, {"name": "DataSet RDDs", "time": 1, "sents": ["Spark does not account for off-heap memory when deciding if/when to drop blocks to ensure enough free memory; consequently, for DataSet RDDs that are larger than the total amount of (off-heap) memory, this can lead to OOM issues."]}, {"name": "Instacart Multitask", "time": 1, "sents": ["This tutorial will be similar to the Instacart Multitask tutorial."]}, {"name": "Scala Versions", "time": 1, "sents": ["Step 3: Check the Scala Versions"]}, {"name": "Layer Parameters Histogram", "time": 1, "sents": ["Model Page: Layer Parameters Histogram"]}, {"name": "Currently Arbiter", "time": 1, "sents": ["Currently Arbiter does not support the ability to create independent layers."]}, {"name": "DL4J RegressionEvaluation", "time": 1, "sents": ["RegressionScoreFunction is used for regression and supports all DL4J RegressionEvaluation metrics (MSE, MAE, RMSE, RSE, PC, R2)."]}, {"name": "Android SDK", "time": 1, "sents": ["It is recommended to upgrade your ProGuard in the Android SDK to the latest release (5.1 or higher)."]}]